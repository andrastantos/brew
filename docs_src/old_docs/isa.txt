ISA
=============================================
There are a few ideas to explore in this processor design:

- We have 15 addressable registers, instead of 16. This allows us to use the 16th code (0xf) to be used as an
  escape to gain all sorts of compact, yet easy to decode spaces in the instruction code
- We have two execution contexts: one, called TASK mode, the other, called SCHEDULER mode
- We don't have interrupt enable/disable instructions. Instead, in TASK mode interrupts are always enabled
  while in SCHEDULER mode interrupts are always disabled
  This means that the processor should spend very little time in SCHEDULER mode, essentially just as much
  as it needs to figure out what to do next, and tee up the appropriate task to handle the situation.
  This is where the naming of the two contexts are coming from: SCHEDULER mode is used for - essentially -
  task switching only, and all useful work (including OS functionality) happens in various TASK contexts.
- Each context has it's own program counter (TPC and SPC).
- Switching between contexts happens using interrupts (TASK -> SCHEDULER), exceptions (TASK -> SCHEDULER)
  and instructions (switches either way).
- Every instruction can be executed with the exact same semantics in both TASK and SCHEDULER mode. Protection
  is achieved by two key concepts:
  - There is a slight imbalance in the ISA: there is a way to influence the current contexts' PC and
    TPC, there is no way to influence SPC (unless of course that happens to be the current context PC)
  - All resources (I/O, memory, even CSRs) are accessed through memory references. These references go through
    an MMU, which controls per-task access rights. This way OS tasks can have higher access to system resources
    then user code. SCHEDULER mode accesses also go through the MMU, but use a different page table address.
    The switch between TASK and SCHEDULER mode MMU page tables is automatic, so when SCHEDULER mode gains
    back execution, it's not limited to the access rights of the last executed task.
- There is no interrupt or exception vector. Instead, when TASK mode execution gets interrupted, SCHEDULER
  mode execution continues from the current SPC. Since the only way to return from SCHEDULER mode to TASK mode
  is by the use of the STU instruction, this means that after an interrupt or exception, executing continues
  in SCHEDULER mode after this STU instruction. SCHEDULER mode code needs to be written as an endless loop,
  where STU can be thought of as a procedure call.
- The ISA strictly operates on the 2-read;1-write port register file principle. This means no PUSH/PULL primitives
  (as PULL would require two writes into the register file).
- The ISA doesn't have CALL/RETURN primitives either (again, return would require two writes).
- Each register has a type associated with it. Unfortunately we don't have decode space to set the type
  during loads, but we do have an instruction to do it after the fact. The ISA specifies that loads don't
  change the type of the destination register. This means that the compiler is best to more-or-less dedicate
  types to certain registers and keep them in that type as long as possible. This would be much easier if
  there were a bunch of registers, with only 15, it might be a little tricky. The type then determines the
  operations associated with various opcodes, especially in the unary, binary ALU groups and in conditional
  branches.
- Type-less variant: if all one needs is a simple integer implementation, types can be simply left out.
  in that case, all instructions will operate as if registers are of INT32 type and the ISA revers back
  to a simple 32-bit integer RISC processor. For this variant, the fractional multiplies in the
  extension group are optional: if not implemented, an SII is thrown, which triggers SW emulation.

INSTRUCTION ENCODING
=============================================

There are three encoding variants:

16-bit instructions:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|    FIELD_D    |    FIELD_C    |    FIELD_B    |    FIELD_A    |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

32-bit instructions:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|    FIELD_D    |    FIELD_C    |    FIELD_B    |    FIELD_A    |  |                         FIELD_E                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

48-bit instructions:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|    FIELD_D    |    FIELD_C    |    FIELD_B    |    FIELD_A    |  |                                                            FIELD_E                                                            |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

FIELD_D normally contains the register index of the [D]estination
FIELD_C normally contains the instruction op-[C]ode
FIELD_B normally contains the register index of the second operand (operand [B])
FIELD_A normally contains the register index of the first operand (operand [A])
FIELD_E normally contains an immediate or a memory offset

The whole 16 bit instruction is referred to as the INST.
The '[]' operator represents sub-fields in verilog notation.
The '{}' operator represents concatenation in verilog notation.
The ':' operator represents range (when that context make sense)

Register indexes:

0x0:  $r0
0x1:  $r1
0x2:  $r2
0x3:  $r3
0x4:  $r4
0x5:  $r5
0x6:  $r6
0x7:  $r7
0x8:  $r8
0x9:  $r9
0xa:  $ra
0xb:  $rb
0xc:  $rc
0xd:  $rd
0xe:  $re
0xf:  reserved

Register aliases:
    $fp:  alias to $r12
    $sp:  alias to $r13
    $lr:  alias to $r14
NOTE: none of these aliases have (almost) anything to do with HW and only make assembly 4
      unambiguous and/or easier to read. The only exception is that $r0 and $r1 support
      special, compact load-store operation. There's no functional difference, but the
      intent is that by using these instructions to access stack-local variables allows
      much more compact code-size (close to ARM THUMB compactness).

NOTE: $pc and $tpc are 31-bit registers: the LSB is ignored on write and always reads as 0.

REGISTER TYPES
=============================================
The type of the data held in a register is stored as side-band information next to the
register data. The meaning of various instruction codes depend on the register types
they operate on.

Since compilers (at least GCC) don't differentiate between signed and unsigned integer
types, the HW doesn't do that either. This means that certain integer operations
have a signed and an unsigned version.

There are up to 15 register types supported by the ISA, but only the following are
in use at the moment:

Type code     Type        Note
--------------------------------------------
0x0           INT32       32-bit integer: this is the default type of all registers after reset
0x1           INT16X2     2-way 16-bit integer vector
0x2           INT8X4      4-way 8-bit integer vector
0x3           UINT16X2S   Unsigned, saturated version on INT16X2
0x4           SINT16X2S   Signed, saturated version on INT16X2
0x5           UINT8X4S    Unsigned, saturated version on INT8X4
0x6           SINT8X4S    Signed, saturated version on INT8X4
0x8           FP32        32-bit float
0x9           FP16X2      2-way 16-bit float vector
0xf           mask        prevents target type changes during type ... <- ... type operations


INSTRUCTIONS NEEDED
=============================================
A good list of instructions supported by CUDA cores:

https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#arithmetic-instructions__throughput-native-arithmetic-instructions

- FP16X2 lane-extract
- Widening/narrowing/lane-extract for fixed point types is easy with the lane-swizzle operation
- maybe lane-swizzle with dynamic sizzle (binary op)?

INSTRUCTION SET
=============================================

In the following tables
- '.' means any value in [0x0:0xe], unless specifically listed as a special case.
      Can be a different number at every occurrence.
- '*' means any value in [0x0:0xf]
      Can be a different number at every occurrence.


ALU operations:
-------------------------------

Form A:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       |       C       |       B       |       A       |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

Exception group

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x0000             FILL     SWI 0                  enters privileged mode, disables interrupts - used to fill unused code-pages; TPC points to the current instruction
0x1000             BREAK    SWI 1                  enters privileged mode, disables interrupts - used for SW breakpoints; TPC points to the current instruction
0x2000             SYSCALL  SWI 2                  enters privileged mode, disables interrupts - used for SYSCALL-s; TPC points to the current instruction
0x3000                      SWI 3                  enters privileged mode, disables interrupts - used for sotware interrupts; TPC points to the current instruction
0x4000                      SWI 4                  enters privileged mode, disables interrupts - used to indicate invlid instructions; TPC points to the current instruction
0x5000                      SWI 5                  enters privileged mode, disables interrupts - used to indicate invlid instructions; TPC points to the current instruction
0x6000             SII      SWI 6                  enters privileged mode, disables interrupts - used to indicate invlid instructions; TPC points to the current instruction
0x7000             HWI      SWI 7                  enters privileged mode, disables interrupts - used to indicate invlid instructions; TPC points to the current instruction

0x8000             STM                             enters task mode, enables interrupts; SPC points to the NEXT instruction
0x9000             WOI                             wake on interrupt
0xa000             SII
0xb000             SII
0xc000             SII
0xd000             SII
0xe000             SII

Atomic group

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x.001             FENCE                        1   ensures that all memory references are completed before continuing

NOTE: inst[12]: ~R-before
      inst[13]: ~W-before
      inst[14]: ~R-after
      inst[15]: ~W-after
      bit-values are inverted to make FIELD_D==0xf an invalid encoding (i.e. no fence specification)
NOTE: on my implementation: reads amongst themselves and writes amongst themselves are always ordered.
      Since reads flush the write-queue, reads after writes are also ordered.
      The only thing that can really happen is if an outstanding read is followed by an independent
      write. If the write happens to the same address, it is caught by the pipeline and serialized,
      but if the write is to a different address, it can go through and hit the write queue.
      Even that might not really happen, I might just serialize writes after reads too.
      So, fences are not really about memory ordering, but other side-effect ordering. What other
      side-effects are there though? All I/O is memory mapped, even MMU and CSR accesses.
      Exceptions and interrupts are not really side-effects. Instruction fetches would be one thing,
      but those are not really caught here either. So... I don't know... Maybe we don't need this at all??
      Actually we do: the write-fence needs to ensure that all the write-responses are back! Just because
      writes leave in-order, they don't necessarily reach their target in order (due to different inter-connected
      latencies to different targets). So W-before will have to not only flush the write queue but also
      wait for all the write-responses to come back, before letting the pipeline continue.


Branch group

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x.002             $pc <- $rD                      <------- indirect jump: we probably want to encode it to something that's easier to recognize by the branch predictor
0x.003             $tpc <- $rD
0x.004             $rD <- $pc
0x.005             $rD <- $tpc
0x.006
0x.007
0x.008
0x.009
0x.00a
0x.00b
0x.00c
0x.00d
0x.00e

Unary group

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x.01.             $rD <- tiny FIELD_A (one-s complement; range is -7...7) ### SHOULD THIS SET RESULT TYPE???
0x.02.             $rD <- $pc + FIELD_A*2  ################## NOTE: WE COULD MAKE THE RANGE A LITTLE HIGHER IF NOT ALLOW 0
0x.03.             $rD <- -$rA
0x.04.             $rD <- ~$rA
0x.05.             $rD <- bsi $rA
0x.06.             $rD <- wsi $rA
-----------
#### TODO: these two should be merged into a single OP.
0x.07.             $rD <- float $rA ### WHAT TO DO FOR 8-bit types????
0x.08.             $rD <- int $rA ### WHAT TO DO FOR 8-bit types????

0x.09.             $rD <- 1 / $rA ### WHAT TO DO FOR 8-bit types????
0x.0a.             $rD <- rsqrt $rA ### WHAT TO DO FOR 8-bit types????
-----------
#### TODO: this is a rather odd-ball instruction.
0x.0b.             $rD <- sum $rA
-----------
0x.0c.             type $rD <- $rA
0x.0d.             $rD <- type $rA
0x.0e.             type $rD <- type FIELD_A

NOTE: We only have reduction sum. Is there any other *really* important reduction op we need?

Binary group

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x.1..             $rD <- $rA ^ $rB       1
0x.2..             $rD <- $rA | $rB       1
0x.3..             $rD <- $rA & $rB       1
0x.4..             $rD <- $rA + $rB       9
0x.5..             $rD <- $rA - $rB       9
0x.6..             $rD <- $rA << $rB      3
0x.7..             $rD <- $rA >> $rB      3
0x.8..             $rD <- $rA >>> $rB     3
0x.9..             $rD <- $rA * $rB       9 (?)
0x.a..             $rD <- ~$rA & $rB      1  (this is for lane-combining with an inverted predicate)
0x.b..             $rD <- tiny $rB + FIELD_A (one's complement; range is -7...7)
0x.c..             see below (stack ops)
0x.d..             see below (stack ops)
0x.e..             see below (mem ops)

NOTE: logical ops ignore type info, except for determining output type
NOTE: if swizzle muxes are inline in the pipeline, instead of a parallel execution unit, it's possible
      to deal with scalar-and-vector combinations, where the scalar gets automatically replicated into
      the right number of lanes before the operation is performed. Similarly, a 2-lane-and-4-lane vector
      situation can replicate the 2-lane vector into 4 lanes before executing the operation.
NOTE: float-and-integer type combinations need to be thought carefully.  Probably +/-/* generate exceptions,
      shifts actually require it (i.e. there $rB has to be integer), logical ops don't care.
NOTE: output type is the type of $rA

Pseudo instructions:
NOP: encodes to 0x2222, which is $r2 = $r2 | $r2
$rD = $rS: encodes to 0xD2SS

Form B:
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       |       C       |       B       | 1 | 1 | 1 | 1 |  |                                                             VALUE                                                             |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION          TYPE VARIATIONS
-------------------------------------------------------------------
0x.00f             $rD  <- VALUE              1 (type of $rD remains unchanged)         NOTE: this is the unary operator space normally. TYPE IS NOT MODIFIED
0x.01f:0x.0df      SII
0x20ef             $pc   <- VALUE                N/A
0x30ef             $tpc  <- VALUE                N/A
0x80ef             type $r0...$r7 <- VALUE
0x90ef             type $r8...$r14 <- VALUE
0x.1.f             $rD  <- VALUE ^ $rB      1
0x.2.f             $rD  <- VALUE | $rB      1
0x.3.f             $rD  <- VALUE & $rB      1
0x.4.f             $rD  <- VALUE + $rB      9
0x.5.f             $rD  <- VALUE - $rB      9
0x.6.f             $rD  <- VALUE << $rB     3
0x.7.f             $rD  <- VALUE >> $rB     3
0x.8.f             $rD  <- VALUE >>> $rB    3              signed right shift
0x.9.f             $rD  <- VALUE * $rB      9 (?)
0x.c.f             see below (stack ops)
0x.d.f             see below (stack ops)
0x.e.f             see below (mem ops)

NOTE: VALUE is assumed to be of the same type as $rB
NOTE: result type is that of $rB (exception for load immediate)

NOTE: << and >> operations where opB is constant can be simulated by multiplies. Because of that, these operations only have one form.
      This does mean though, that the constant needed for certain shifts is larger than what would normally be required
      (i.e. 32-bit instead of 16).

Form C:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       |       C       | 1 | 1 | 1 | 1 |       A       |  |                         VALUE                                 |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION                TYPE VARIATIONS
-------------------------------------------------------------------------
### SHOULD LOAD IMMEDIATE SET THE TYPE?
0x.0f0             $rD  <- short VALUE                1     NOTE: this is the unary operator space normally.
0x.0f0:0x.0fd      SII
0x20fe             $pc  <- short VALUE
0x30fe             $tpc <- short VALUE
0x.1f.             $rD  <- short VALUE ^ $rA          1
0x.2f.             $rD  <- short VALUE | $rA          1
0x.3f.             $rD  <- short VALUE & $rA          1
0x.4f.             $rD  <- short VALUE + $rA          9
0x.5f.             $rD  <- short VALUE - $rA          9
0x.6f.             $rD  <- short VALUE << $rA         3
0x.7f.             $rD  <- short VALUE >> $rA         3
0x.8f.             $rD  <- short VALUE >>> $rA        3    signed right shift
0x.9f.             $rD  <- short VALUE * $rA          9 (?)
0x.af.             $rD  <- lane_swizzle $rA, VALUE    1     only lower 8 bits of value has any meaning, all selection options are valid, independent of type NOTE: in ASM, this is represented as a 4-digit number, each digit of the value 0...3, representing each lane, so for instance 0000 would replicate byte 0 into all 4 bytes
0x.bf.             SII
0x.cf.             see below (stack ops)
0x.df.             see below (stack ops)
0x.ef.             see below (mem ops)

NOTE: VALUE is assumed to be of matching scalar type for $rA. It is sign-extended to 32-bits, then replicated for each lane.
NOTE: result type is that of $rA (exception for load immediate)

VALUE is *always* sign-extended to 32-bits before applying it to the operation.
TODO: we might want to zero-extend for certain operations, such as logical ops.
NOTE: sign-extending a 16-bit constant, then treating it as a float almost certainly don't make any sense.
TODO: The last three op-codes could be used for something else, such as the missing shifts though...

Branches:
-------------------------------

Form A:

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 |       C       |       B       |       A       |  |                          OFFSET                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION                                   TYPE VARIATIONS
------------------------------------------------------------------------------------------
0xf00.            if any $rA == 0  $pc <- $pc + unmunge(OFFSET)          1
0xf01.            if any $rA != 0  $pc <- $pc + unmunge(OFFSET)          1
0xf02.            if any $rA < 0  $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf03.            if any $rA >= 0 $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf04.            if any $rA > 0  $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf05.            if any $rA <= 0 $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf06.            SII
0xf07.            SII
0xf08.            if all $rA == 0  $pc <- $pc + unmunge(OFFSET)          1
0xf09.            if all $rA != 0  $pc <- $pc + unmunge(OFFSET)          1
0xf0b.            if all $rA >= 0 $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf0c.            if all $rA > 0  $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf0d.            if all $rA <= 0 $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf0a.            if all $rA < 0  $pc <- $pc + unmunge(OFFSET)           5                signed compare
0xf0e.            SII

0xf1..            if any $rB == $rA   $pc <- $pc + unmunge(OFFSET)       1
0xf2..            if any $rB != $rA   $pc <- $pc + unmunge(OFFSET)       1
0xf3..            if any signed $rB < $rA  $pc <- $pc + unmunge(OFFSET)  5             signed compare
0xf4..            if any signed $rB >= $rA $pc <- $pc + unmunge(OFFSET)  5             signed compare
0xf5..            if any $rB < $rA    $pc <- $pc + unmunge(OFFSET)       5
0xf6..            if any $rB >= $rA   $pc <- $pc + unmunge(OFFSET)       5
0xf7..            SII
0xf8..            SII
0xf9..            if all $rB == $rA   $pc <- $pc + unmunge(OFFSET)       1
0xfa..            if all $rB != $rA   $pc <- $pc + unmunge(OFFSET)       1
0xfb..            if all signed $rB < $rA  $pc <- $pc + unmunge(OFFSET)  5             signed compare
0xfc..            if all signed $rB >= $rA $pc <- $pc + unmunge(OFFSET)  5             signed compare
0xfd..            if all $rB < $rA    $pc <- $pc + unmunge(OFFSET)       5
0xfe..            if all $rB >= $rA   $pc <- $pc + unmunge(OFFSET)       5

NOTE: for scalar types, FIELD_C MSB (inst[15]) is irrelevant, that is any/all selection doesn't matter
NOTE: comparison type is determined by type of $rA. type of $rB is ignored and assumed to match that of $rA
TODO: maybe we can do lane-replication in case of lane-count mismatch? After all, these are using the ALUs, the same way as binary ops do...

PSEUDO OPS:
    if signed $rB >= $rA $pc <- $pc + unmunge(OFFSET)
    if signed $rB < $rA  $pc <- $pc + unmunge(OFFSET)
    if $rB >= $rA   $pc <- $pc + unmunge(OFFSET)
    if $rB < $rA    $pc <- $pc + unmunge(OFFSET)

unmunge: move LSB to bit position 17, replace LSB with 0 and sign-extend to 32 bits.

Form B (group CA):

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 |       C       | 1 | 1 | 1 | 1 |       A       |  |                          OFFSET                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION                                   TYPE VARIATIONS
------------------------------------------------------------------------------------------
0xf0f.        if $rA[0]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf1f.        if $rA[1]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf2f.        if $rA[2]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf3f.        if $rA[3]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf4f.        if $rA[4]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf5f.        if $rA[5]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf6f.        if $rA[6]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf7f.        if $rA[7]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf8f.        if $rA[8]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xf9f.        if $rA[9]  == 1 $pc <- $pc + unmunge(OFFSET)               3
0xfaf.        if $rA[14] == 1 $pc <- $pc + unmunge(OFFSET)               3
0xfbf.        if $rA[15] == 1 $pc <- $pc + unmunge(OFFSET)               3
0xfcf.        if $rA[16] == 1 $pc <- $pc + unmunge(OFFSET)               3
0xfdf.        if $rA[30] == 1 $pc <- $pc + unmunge(OFFSET)               3
0xfef.        if $rA[31] == 1 $pc <- $pc + unmunge(OFFSET)               3

OFFSET is sign-extended to 31 bits, shifted left by one before addition.

Form C (group CB):

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 |       C       |       B       | 1 | 1 | 1 | 1 |  |                          OFFSET                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION                                   TYPE VARIATIONS
------------------------------------------------------------------------------------------
0xf0.f        if $rB[0]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf1.f        if $rB[1]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf2.f        if $rB[2]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf3.f        if $rB[3]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf4.f        if $rB[4]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf5.f        if $rB[5]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf6.f        if $rB[6]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf7.f        if $rB[7]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf8.f        if $rB[8]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xf9.f        if $rB[9]  == 0 $pc <- $pc + unmunge(OFFSET)               3
0xfa.f        if $rB[14] == 0 $pc <- $pc + unmunge(OFFSET)               3
0xfb.f        if $rB[15] == 0 $pc <- $pc + unmunge(OFFSET)               3
0xfc.f        if $rB[16] == 0 $pc <- $pc + unmunge(OFFSET)               3
0xfd.f        if $rB[30] == 0 $pc <- $pc + unmunge(OFFSET)               3
0xfe.f        if $rB[31] == 0 $pc <- $pc + unmunge(OFFSET)               3

OFFSET is sign-extended to 31 bits, shifted left by one before addition.

NOTE: in the branch predictor, relative jumps with negative OFFSET VALUE can be assumed to be taken by default.
      Compilers are encouraged to encode back-edges of loops in this encoding to improve branch prediction.

NOTE: some bit-offsets for certain lane types are meaningless. In those cases, the bits to be compared are assumed to be 0.

Stack ops
-------------------------------

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       |       C       |            OFS            | A |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA             OP_CODE   OPERATION               TYPE VARIATIONS
------------------------------------------------------------------------
0x.c**             MEM[$rA,tiny OFS*4] <- $rD        1
0x.d**             $rD <- MEM[$rA,tiny OFS*4]        1 (destination type remains unchanged)

NOTE: these instructions only allow $r0 ($sp) and $r1 ($fp) as their base register and an offset range of -256...+252.
NOTE: the existence of these ops complicate memory op decode as well as operation size decode, but save
      a *huge* amount of code-space, allowing almost all register spills and fills to be done in two bytes.

Load/Store
----------

Form A: Indirect load/store

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       | 1 | 1 | 1 | 0 |     MEM_OP    |       A       |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA        OP_CODE                        OPERATION
--------------------------------------------------------------
0x.e0.        type $r0...$r7  <- MEM[$rD, FIELD_A*4 (one-complement)]
0x.e1.        type $r8...$r14 <- MEM[$rD, FIELD_A*4 (one-complement)]
0x.e2.        MEM[$rD, FIELD_A*4 (one-complement)] <- type $r0...$r7
0x.e3.        MEM[$rD, FIELD_A*4 (one-complement)] <- type $r8...$r14
0x.e4.        $rD <- MEM8[$rA]               8-bit unsigned load from MEM[$rA] into $rD
0x.e5.        $rD <- MEM16[$rA]              16-bit unsigned load from MEM[$rA] into $rD
0x.e6.        $rD <- MEM[32][$rA]            32-bit load from MEM[$rA] into $rD
0x.e7.        $rD <- MEMLL[32][$rA]          32-bit unsigned load-reserve (exclusive load)
0x.e8.        MEM8[$rA] <- $rD               8-bit store to MEM[$rA] from $rD
0x.e9.        MEM16[$rA] <- $rD              16-bit store to MEM[$rA] from $rD
0x.ea.        MEM[32][$rA] <- $rD            32-bit store to MEM[$rA] from $rD
0x.eb.        MEMSR[32][$rA] <- $rD          32-bit store-release (exclusive store)
0x.ec.        $rD <- SMEM8[$rA]              8-bit signed load from MEM[$rA] into $rD
0x.ed.        $rD <- SMEM16[$rA]             16-bit signed load from MEM[$rA] into $rD
0x1ee.        INV[32][$rA]                   invalidate cache line for address $rA
0x2ee.        $pc <- MEM[32][$rA]            32-bit load from MEM[$rA] into $PC
0x3ee.        $tpc <- MEM[32][$rA]           32-bit load from MEM[$rA] into $TPC

NOTE: loads don't change the type of a register.

Form B: Inidirect offset load/store

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       | 1 | 1 | 1 | 1 |     MEM_OP    |       A       |  |                           VALUE                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA        OP_CODE                        OPERATION
--------------------------------------------------------------
0x.f0.        type $r0...$r7  <- MEM[$rD, FIELD_A*4 (one-complement)] with VALUE as mask
0x.f1.        type $r8...$r14 <- MEM[$rD, FIELD_A*4 (one-complement)] with VALUE as mask
0x.f2.
0x.f3.
0x.f4.        $rD <- MEM8[$rA+VALUE]               8-bit unsigned load from MEM[$rA+VALUE] into $rD
0x.f5.        $rD <- MEM16[$rA+VALUE]              16-bit unsigned load from MEM[$rA+VALUE] into $rD
0x.f6.        $rD <- MEM[32][$rA+VALUE]            32-bit load from MEM[$rA+VALUE] into $rD
0x.f7.        $rD <- MEMLL[32][$rA+VALUE]           32-bit unsigned load-reserve (exclusive load)
0x.f8.        MEM8[$rA+VALUE] <- $rD               8-bit store to MEM[$rA+VALUE] from $rD
0x.f9.        MEM16[$rA+VALUE] <- $rD              16-bit store to MEM[$rA+VALUE] from $rD
0x.fa.        MEM[32][$rA+VALUE] <- $rD            32-bit store to MEM[$rA+VALUE] from $rD
0x.fb.        MEMSR[32][$rA+VALUE] <- $rD           32-bit store-release (exclusive store)
0x.fc.        $rD <- SMEM8[$rA+VALUE]              8-bit signed load from MEM[$rA+VALUE] into $rD
0x.fd.        $rD <- SMEM16[$rA+VALUE]             16-bit signed load from MEM[$rA+VALUE] into $rD
0x1fe.        INV[32][$rA+VALUE]                   invalidate cache line for address $rA+VALUE
0x2fe.        $pc <- MEM[32][$rA+VALUE]            32-bit load from MEM[$rA+VALUE] into $PC
0x3fe.        $tpc <- MEM[32][$rA+VALUE]           32-bit load from MEM[$rA+VALUE] into $TPC

NOTE: VALUE is sign-extended before addition
NOTE: loads don't change the type of a register.

Form C: Direct load/store

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|       D       | 1 | 1 | 1 | 1 |     MEM_OP    | 1 | 1 | 1 | 1 |  |                                                             VALUE                                                             |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

  FIELD
  DCBA        OP_CODE                        OPERATION
--------------------------------------------------------------
0x.f0f
0x.f1f
0x.f2f
0x.f3f
0x.f4f        $rD <- MEM8[VALUE]               8-bit unsigned load from MEM[VALUE] into $rD
0x.f5f        $rD <- MEM16[VALUE]              16-bit unsigned load from MEM[VALUE] into $rD
0x.f6f        $rD <- MEM[32][VALUE]            32-bit load from MEM[VALUE] into $rD
0x.f7f        $rD <- MEMLL[32][VALUE]           32-bit unsigned load-reserve (exclusive load)
0x.f8f        MEM8[VALUE] <- $rD               8-bit store to MEM[VALUE] from $rD
0x.f9f        MEM16[VALUE] <- $rD              16-bit store to MEM[VALUE] from $rD
0x.faf        MEM[32][VALUE] <- $rD            32-bit store to MEM[VALUE] from $rD
0x.fbf        MEMSR[32][VALUE] <- $rD           32-bit store-release (exclusive store)
0x.fcf        $rD <- SMEM8[VALUE]              8-bit signed load from MEM[VALUE] into $rD
0x.fdf        $rD <- SMEM16[VALUE]             16-bit signed load from MEM[VALUE] into $rD
0x1fef        INV[32][VALUE]                   invalidate cache line for address VALUE
0x2fef        $pc <- MEM[32][VALUE]            32-bit load from MEM[VALUE] into $PC
0x3fef        $tpc <- MEM[32][VALUE]           32-bit load from MEM[VALUE] into $TPC

NOTE: loads don't change the type of a register.


Extension group A:
-------------------------------

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |      EXT      |  |       D       |       C       |       B       |       A       |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

These instructions allow for instruction set extensions in the following way: each value of the ESC select an alternative decoding
of the following 16-bits. Since these 16 bits could further allow for an up to 32-bit FIELD_E value, the total instruction length
could be 64 bits. For now, only the following operations are defined:

NOTE: as of now, the simple instruction length decode logic below holds true, even for the extension group: the only defined instructions
are 32-bit long, which is what the length decoding logic signals.


EXT = 0:
  FIELD
  DCBA             OP_CODE   OPERATION             TYPE VARIATIONS
------------------------------------------------------------------------------------------
0x.00.            $rD <- $rA == 0              3
0x.01.            $rD <- $rA != 0              3
0x.02.            $rD <- $rA < 0               5         signed compare
0x.03.            $rD <- $rA >= 0              5         signed compare
0x.04.            $rD <- $rA > 0               5         signed compare
0x.05.            $rD <- $rA <= 0              5         signed compare
0x.06.            SII
0x.07.            SII
0x.08.            SII
0x.09.            SII
0x.0a.            SII
0x.0b.            SII
0x.0c.            SII
0x.0d.            SII
0x.0e.            SII

0x.1..            $rD <- $rB == $rA           3
0x.2..            $rD <- $rB != $rA           3
0x.3..            $rD <- signed $rB < $rA     5              signed compare
0x.4..            $rD <- signed $rB >= $rA    5              signed compare
0x.5..            $rD <- $rB < $rA            5
0x.6..            $rD <- $rB >= $rA           5
0x.7..            SII
0x.8..            SII
0x.9..            SII
0x.a..            SII
0x.b..            SII
0x.c..            SII
0x.d..            SII
0x.e..            SII

EXT = 1:
0x.0..             $rD <- interpolate $rA, $rB

Extension group B:
-------------------------------

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |    EXT    |      FIELD_F      |  |       D       |       C       |       B       |       A       |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

EXT = 0:
  FIELD
  DCBA             OP_CODE   OPERATION                  TYPE VARIATIONS
------------------------------------------------------------------------------------------
0x.0..             $rD <- full $rA * $rB >>> FIELD_F    3
0x.1..             $rD <- full $rA * $rB >> FIELD_F     3

Extension group C:
-------------------------------

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|     TYPE_A    | 1 | 1 | 1 | D | 1 | 1 | 1 | 1 |    TYPE_B     | ...
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

type override for $rA (TYPE_A) and $rB (TYPE_B). If D is set, $rD type is written
back into the register file. If cleared, $rD's type is not changed.

This is a *PREFIX* instruction. It works the following way:
The next instruction will assume that $rA and/or $rB is of TYPE_A and TYPE_B respectively.
That is, this instruction overrides the type-info that comes from the register file for the
next instruction.

In order to be interrupt safe, this instruction disables interrupts for a single cycle
(or decoded together with the subsequent instruction). In order to prevent user-code to lock
the core indefinitely, this instruction, *toggles* the interrupt-suppression bit. This means
that a pending interrupt at worst gets delayed by one instruction.

Exceptions are a slight problem still: if the subsequent instruction generates an exception and
the supervisory code attempts to retry, it'll have to be aware of the prefix and retry from that
position. This could be problematic, since we can't simply check the previous word in the handler:
we can't know if that was really part of the instruction stream. What we should probably do is
to save the prefix instruction counter in some place that the handler has access to. If we're
certain that only a single prefix can ever be applied, it's also possible to record that fact in the
LSB of the exception address. Alternatively, we could record the exception address as the address
of the (first) prefix instruction, in which case the handler would need to skip forward to see
the complete instruction. This solution jives better with the 'decode together' idea.

Unused extension groups:
-------------------------------

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 |      EXT      | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |  |                           VALUE                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

THIS IS TREATED AS A CBRANCH BY THE BRANCH PREDICTOR !!!!

SII

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |  |                           VALUE                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

SII

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |      EXT      | 1 | 1 | 1 | 1 |  |                           VALUE                               |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

SII

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|      EXT      |      EXT2     | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |  |                                                             VALUE                                                             |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

EXT2 can't be 0xc or 0xd!!!!

SII

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|      EXT      | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |  |                                                             VALUE                                                             |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

SII

+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|      EXT      | 1 | 1 | 1 | 0 |      EXT2     | 1 | 1 | 1 | 1 |  |                                                             VALUE                                                             |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+  +---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+

IF EXT == 0x2 && EXT2 == 0xe, THIS IS TREATED AS A CBRANCH BY THE BRANCH PREDICTOR !!!!

SII

DECODE NOTES:
=============

Instruction encoding is such that the following condition can be used to determine if the FIELD_E is needed:
  FIELD_D == 0xf ||
  (FIELD_C == 0xf && (FIELD_B != 0xf || FIELD_A == 0xf)) ||
  (FIELD_C == 0xe && FIELD_A == 0xf) ||
  (FIELD_C < 0xc && (FIELD_B == 0xf || FIELD_A == 0xf))

The size of FIELD_E == 16 if:
  FIELD_D == 0xf || FIELD_A != 0xf

Branches can be identified by:
  (FIELD_D == 0xf         && FIELD_C != 0xf) ||
  ((FIELD_D & 0xe) == 0x2 && (FIELD_C & 0xe) == 0xe && FIELD_B == 0xe) ||
  ((FIELD_D & 0xe) == 0x2 && FIELD_C == 0x0         && (FIELD_B & 0xe) == 0xe && (FIELD_A & 0xe) == 0xe && (FIELD_B & 1 != FIELD_A & 1) ||
  (FIELD_C == 0x0         && FIELD_B == 0x0         && (FIELD_A & 0xe) == 0x2) ||
  ((FIELD_D & 0x8) == 0   && FIELD_C == 0x0         && FIELD_B == 0x0         && FIELD_A == 0x0) <-- SWI insn.
  (FIELD_D == 0x8         && FIELD_C == 0x0         && FIELD_B == 0x0         && FIELD_A == 0x0) <-- STM insn.

  Some simplifcations can be made if this monster turns out to be a problem, such as not predicting SWI and STM
  instructions. Notice, how term 3 has an XOR at the very end. This term can be decomposed into 2 4-term AND
  expressions, for essentially 0x20ef and 0x20fe (plus the 0x3... variants).
  In essense the critical path is a 16-bit compare followed by 6-way OR (for the full term) and a
  15-bit compare followed by a 4-way OR (for the simplified term).

  It seems that Cyclone V has 5-bit LUTs. That would mean that one can compare 15 bits in 3 LUTs. Then, another LUT could be used
  to generate a single output bit. That is to say a 15-bit comparator has a 2-LUT latency. The 4 comparators can be combined in a
  single LUT, so the total decode latency is 3 LUTs. Since we have unused inputs on some of the LUTs, it's possible that the full
  term can also be decoded in that much latency.

NOTE: all these terms are simulated. The data latency seems to be a little over 5.5ns in the fastest Cyclone V parts. That would put
      us below 200MHz clock frequency. However, due to clock also getting delayed we actaully get a significant boost and timing
      closes all the way up to 421MHz. From the technology viewer it seems that the logic needs three levels of LUTs. So, I was right:
      only three levels of LUTs are needed. This would give us roughly 1.83ns delay per LUT, or 545MHz f_max.
NOTE:
========
CALLs use link registers:
$lr <- $pc+<offset>
$pc <- <callee>

<offset> could be 8, 6 or 4, depending on the encoding size of the call.

Upon entry callee saves $lr if needed (along with all other callee-saved registers per the ABI)
Upon return, all saved registers (including $lr) are restored, then:

RETURN:
$pc <- $r2

Notice how this is only one instructions longer than the traditional link approach as the
stack-adjustment and the save/restore of the link register would be there in most cases anyways.
The splitting of the link into two instruction allows us to not have two forms of all possible
branches, and so all possible branches *can* be calls as well.

INTERPOLATION
=============================================
2D interpolation works the following way:
-----------------------------------------
Inputs:
1. Base and stride register. The lower 4 bits determine
   output (and texture data) type. The next 4 bits determine
   the stride as a power of 2, such that value 0 is a stride
   of 2 and value 15 is 65536. Stride is measured in 32-bit
   quantities. The top 24 bits determine the 256-byte aligned
   base address for the texture.
2. Coordinates. Encoded in (U)FR12P4x2 format, it's two unsigned
   elements denote the fractional coordinates within the texture
3. Element type can be the following:
        SINT32     - ?
        UINT32     - ?
        SINT16     - mono audio processing
        UINT16     - ?
        SINT8      - bump maps
        UINT8      - mono images
        SINT16X2   - stereo audio processing
        UINT16X2   - ?
        SINT8X4    - ?
        UINT8X4    - RGBA images
   NOTE: element types are different from register types due to the
         different needs.
Operation:
1. The four neighbor coordinates are computed and their four 32-bit
   values are loaded.
2. Interpolation is performed between the four values (lane-by-lane)
   using the fractional values of the coordinates. By the nature of the
   operation, the results can't overflow, but signed-ness matter
3. The result is written into the output register
Output:
1. The interpolated value (lane-by-lane)

Overall, this is a binary operation, albeit one that involves 4 memory
reads as well. As such, it's anything but a RISC operation. Probably,
just as others have done it, it should be a tack-on execution unit.

Another (not much better) way of dealing with the problem is to say that the
base/stride registers' lowest 2 bits describe the output type, but that would
mean that the 2D alignment stride will become 64-byte aligned, because the
bottom 6 bits are now used for other stuff.

At the same time, maybe other operations could also benefit from looking at the
result type? Well, here's why they shouldn't: That effectively creates a 3rd
read port into the register file! Our BRAMs are organized as 36-bit wide, so
the type info comes with the value. Now, how would we know the result type??

Maybe even multi-cycle, instead of fully pipelined?

1D interpolation works the following way:
-----------------------------------------
Inputs:
1. Base register. This now simply is a 32-bit DWORD-aligned pointer.
2. Coordinate: Encoded as a (U)FR24P8 value.
3. Element type. Supported values:
        INT32 (signed interpolation),
        INT16X2 (signed interpolation),
        INT8X2 (unsigned interpolation)
Operation:
1. The two neighbor coordinates are computed and their 32-bit values are loaded
2. Interpolation is performed lane-by-lane.
3. The result register is written
Output:
1. The interpolated value (lane-by-lane)

A single binary opcode could be used to encode all of this, because the type
of the coordinate register can be used to determine the 1D/2D interpolation
and the result register type could be used to determine the interpolation type.

This is a bit unusual though: most operations *determine* the output type, while
this one requires it to be set a priori.

SYNCHRONIZATION
===============

GPUs have a *ton* of synchronization operations, but I don't think any of
them are really necessary. The LL/SC primitives with controlled cache-invalidation
and some TCMs for quick access should suffice and would allow to emulate anything
we might want.

At any rate, some material on the subject:
https://gpuopen.com/gdc-presentations/2019/gdc-2019-agtd5-breaking-down-barriers.pdf
https://mynameismjp.wordpress.com/2018/03/06/breaking-down-barriers-part-1-whats-a-barrier/ - write-up of the same slide-deck

Barriers
========
Barriers are between kernels (if needed). The idea is that one kernel should completely
finish before another can start. This is at the level of the thread scheduler, but I think
it still can be implemented, using LL/SC quite easily:

Let's say that Kernel B depends on Kernel A, so none of Kernel Bs threads can start before
all of Kernel As threads completed.

1. The thread scheduler writes the number of threads in Kernel A into a memory location
2. The thread scheduler starts scheduling threads of Kernel A
3. At the end of each thread of Kernel A, an atomic decrement is performed on the thread
   count from (1)
4. The thread scheduler doesn't schedule any threads of Kernel B, until Kernel As counter
   is 0.

This allows for more complex dependency graphs as well as long as each kernel has an individual
counter like that. It also allows the scheduler to keep scheduling threads from independent
threads as long as there is work to be done and still observe the dependencies.

Cache invalidation
==================
I originally thought cache-invalidation should be a (memory mapped) I/O instruction, but I'm not sure
anymore. In reality, it could be rather easily encoded and by flagging a bit in the transaction, the
cache knows it needs to invalidate the line in case of a hit. This also goes through the normal
logical->physical address translation path, which is an extra benefit.

There's still no way to invalidate a single line of the ICache or special instructions to completely
blow away either caches. Those are still available through memory-mapped I/O.

LL/SC implementation
====================
We are taking advantage of the AXI4 exclusive transactions. These are designed to implement exactly these
primitives: https://developer.arm.com/documentation/102202/0200/Atomic-accesses

This pushes the burden of actually making things work to the memory controller(s) but hopefully there's
support for it there already. If not, the following can be done:

- Let's have a BRAM in 8kx1-bit config. The BRAM address is a 13-bit hash of the transaction address.
- The data is a single 'valid' bit.
Operation:
- On exclusive load, the valid bit is set for the corresponding address.
- On exclusive store, the valid bit is checked and the store is cancelled if the bit is clear.
  The valid bit is cleared either way.

If there are multiple ports to a memory, each port will have to have a copy of the above mechanism for each port.
That is to say, the number of BRAMs needed is the number of ports squared.

Each exclusive load on any port sets all the valid bits in the BRAMs for that port.
Each exclusive store does three things:
1. checks if all the bits are set in the BRAMs for that port. If any if cleared, the write fails.
2. simultaneously, clears the valid bit on all *other* ports' BRAMs that are assigned to this port
3. clears the valid bit in the BRAMs (maybe one of them is sufficient) for this port

This protocol I think leaves one cycle uncertainty, that needs to be checked: if a write to the same address
happens in the same cycle on two or more ports, they could still sneak through. This can be avoided if the BRAMs
are operated in 'read-new-value' conflict resolution mode.

SC needs to return a result code, which comes with the write-response on AXI4. Thus, SC stalls until that comes
back, in effect, flushing the write queue.

With this, an atomic increment would look something like this:

retry:
    $rD <- ! MEM[$rA,<ofs>]
    $rD <- $rD + 1
    $rD <- ? MEM[$rA,<ofs>] <- $rD
    if $rD != 0 $pc <- retry # to mimic RiscV behavior, we signal success with 0.

More complex primitives, can be built out of this simple one. Many architectures add things like atomic increment
as a single instruction, the idea being that one can avoid all the traffic between the processor and the memory
controller if these primitives are implemented right there. I don't want to go that far, so I don't have any
of the primitives.


AMD ISA NOTES
=============================

HA! AMD actually documents their ISA:
https://developer.amd.com/wp-content/resources/RDNA2_Shader_ISA_November2020.pdf
https://gpuopen.com/amd-isa-documentation/

There are a lot of data types (especially for textures!!!!), and a lot of memory types.
There seems to be a TCM (they call it LDS). They also seem to indicate that L1 caches
are write-through (thus the benefit of TCM in data-sharing). LDS is shared within a
'work group'. A work-group is whatever is executing on up to 4 SIMD engines, where
each SIMD engine can have up to 32 workitems (thread, maybe?). I don't see any SMT
features on a per CU level, but there is something about it in the 'dispatch processor'.
So, the 32 workitems then must be the SIMT lanes. Vector registers are 32-bit wide, which
would mean that they are per-lane. There seems to be 256 addressable vector registers
and 106 scalar registers (these are NOT per lane). All of these are 32-bit wide.

There are sub-vector data-types (16-bit, two-lanes-in-one-reg) variants.

There is some confusion about register counts in the block diagram and the ISA. That might
have something to do with SMT. If so, there seems to be 4-way SMT capability in the CUs.

The instruction set is mainly a 32-bit one, but with lots of 64-bit or even longer
instructions, especially for vector ops. Some are even 128+bits long!

There are 16 atomic instructions (add/sub...)

Page 91 contains a good diagram of the memory hierarchy.

This thing is anything but simple. There are a *TON* of instructions.

More on synchronization: there is an S_SLEEP and S_WAKEUP pair.
S_BARRIER - thread-group thingy. There is some verbiage around non-created
      and terminated waves.
S_ICACHE_INV - invalidates the whole ICache
S_DCACHE_INV - invalidates the whole (scalar) L0 DCache
S_GL1_INV    - invalidates the GL1 cache whatever that is

NOTE: there's no flush. That seems to indicate:
  - write-through
  - non-coherent

BENCHMARK NOTES
==================

Linpack.o: 3411 assembly lines, 6640 bytes of code. That's pretty close to 16-bits per instruction.
And that's before the spill/reload optimizations. That alone would save 774 words or 1584 bytes.
That would make the code segment 5056 bytes long, so below 16 bits per instruction (which of course
must be a measurement error, I can't average below 16.)

The problem is in the code segment size. Whatever is disassembled is only 11498 bytes long, because it
contains both .text and .text.startup. So, the real ratio used to be 27 bits/instruction.

After the changes it should be around 23.2 bits/instruction. A 32-bit ISA obviously would not be
able to beat that, but it might still be better if it somehow was significantly more compact.

One reason for that to be would be the possibility of 31 GP registers. On the flip-side, loading
a generic 32-bit constant would require 64-bits of instruction space, whereas this ISA gets the
job done if 48 bits.

Overall, I have a hard time seeing how any 32-bit ISA would be able to beat this for compactness.
But then again, there's RISCV...

The same metrics for that code: 2137 instructions, in 8540 bytes. That's quite precisely 32-bits per
instruction, which of course is the expectation. Though the comparison isn't fair: the RISCV code
uses hard-floats.

Correcting for that, we end up with 3334 instructions, 13328 bytes. Now we're talking! the RISCV
ISA now doesn't match up to even my current implementation, let alone to the optimized one!

The other 32-bit architectures, NIOS2 and MICROBLAZE were no better either. That leaves ARM (32),
which appears to still be slightly better.

That stems from the fact that they manage to accomplish the task in a mere 2724 instructions. However
we do know that ARM is very compact due to the their multi-register push/pull instructions, which
I'm not willing to entertain. And with the optimized spill/reload sequences, I'll be able to beat
ARM as well, even though not THUMB.

The typed ISA though is *painful*!