On top of the core, the following system components are important for the implementation:

OS NOTES:
===========
The 'scheduler' context is primarily used for interrupt processing (that is to decide which task to schedule after a particular interrupt)

OS functions are implemented as tasks, though of course the scheduler context is part of it as well. That is to say, the only reason OS
tasks have more priviledge then user ones is because of the way the MMU is set up, since everything (including CSRs) are memory-mapped.

The scheduler context is not any special in terms of memory access rights as anything else: it also goes through the MMU, it's just that
it's pages are set up such that it can access more stuff.

There are only two important differences:
1. The scheduler always runs with interrupts disabled. All tasks run with interrupts always enabled.
2. There is a slight asymmetry in the ISA: every context can change their own PC, or the TPC, but only
   the scheduler can influence SPC (by virtue of it being it's own PC)

The consequence of this design is that SYSCALLs need to transition into scheduler mode and out of it again (and the same on the way back).
This essentially mean twice as many task switches as a reguler ring-based (monolithic kernel) OS design would need. However, the benefit
gets reatly reduced if you consider that every SYSCALL is an opportunity to sleep the current task and wake a different one. That is because
many SYSCALLs deal with I/O which are inherently slow, so you would want to get someone else running while the I/O is doing its thing in
the background. Very quick SYSCALLs can be handled in the scheduler completely, but be careful: interrupts are disabled the whole time.

At any rate, task context switch shold be very quick in order to make this architecture anywhere remotely performant.

1. Save registers into the task control block (use the MMU to map that into a fixed logical address of the scheduler)
2. Determine source of interrupt (read interrupt cause register)
3. Determine task to handle interrupt
4. Re-jiggle MMU config for new task
5. Load registers from new tasks control block (again, new MMU config is already such that it's mapped into a fixed logical address)
6. STU - this returns control to the new task
7. jump to step 1.

Most of the penalty comes from the load/restore of register content and the fact that we're changing the MMU config (which might
wreck havoc with the caches).

INTERCONNECT
============
We should have self-describing HW, I think. That would mean that the highest few bytes of anything in the address space should
say what that thing is.

Now, this is not possible for all things (memories for example), so the interconnect should step in for those items.

'Things' are identified by UUIDs, which are 128-bit long.

The interconnect also contains a descriptor of the following format:

32-bit region length (32-bit aligned)
32-bit region start (32-bit aligned)
Optional 128-bit UUID for region, if LSB of region start is set

The table is read backwards from the highest offset (which is the interconnect UUID) and read until region-length 0 is enocuntered.
Regions must not be overlapping, but they are not necessarily listed in any particular order.

Region length 0 terminates the scan.

Each subsection either contains its own UUID or the UUID is in the interconnect descriptor one level above.

This setup allows SW to completely scan and understand the address map of the HW without any prior knowledge. (NOTE: since the tables
and IDs are hard-coded, there's no HW complexity involved in coding it, except of course for the need of actually storing it)

NOTE: most peripherals simply need to have a 128-bit read-only register, containing their UUID decoded at their highest addressable
I/O region. If peripherals also have memory mapped memories, those are described by the interconnect.

NOTE: new UUIDs need to be generated and used for every generation of the IPs. Even (SW-visible) bug-fixes should require a new UUID.

!!!!!!!!!!!!!!!!!!!
This needs thought, way more though. The UUID apprach gives you exact HW versioning, but not revisioning or any sort of capability
listing. Thus, any minor HW change would require a complete SW recompile. There's no backwards compatibility what so ever. So, maybe
a list of compatible UUIDs? But then how long is the list? What if there's partial compatibility with some other IP? (Such as two
interconnects that have completely different control mechanisms (thus different UUIDs), but would still need to support the above
discovery process.
!!!!!!!!!!!!!!!!!!!


BOOT NOTES:
===========
On reset, we start in SCHEDULER mode, at (logical) address 0. This generates a TLB mis-compare upon address translation. The MMU page table address is also set to 0, so the first entry of the
top-level page table is loaded from physical address 0. Based on that, the second-level (if that's how it is set up) page table enry is also loaded, from whatever address (say 4096).
At this point the physical address for the first instruction can be determined (say 8192) and the fetch can progress. The end result is that we can boot the machine with all registers defaulting to 0.

This does mean though that the first 8kB of the boot code must be page tables and also that a completely linear address mapping is not really possible, at least not immediately upon boot. I
don't think that's a huge loss. The 8kB page table set is enough to set up:
- LA_00000000...LA_00001FFF maps to PA_00002000...PA_00003FFF
- LA_00002000...LA_00003FFF maps to PA_00000000...PA_00001FFF
- All other pages map linearly
Furthermore, since SBASE and TBASE both default to 0, it's possible to enter TASK mode to handle interrupts without the complexities of address translation in the early boot process.

I/O AND CSR NOTES:
==================
I guess these all need to be memory mapped if we don't want to have all sorts of fun with new instructions. They probably would occupy high ranges of the physical address space, so that they don't
interfere with booting. The difference between CSRs and I/O is that there is one copy of CSRs for each processor (in a multi-processor system) while there is only one copy of I/O. This is something
that can be handled on the interconnect level (CSR peripherals are replicated and the CPUID is pre-pended to the physical address comming out of the CPUs).

CSRs occupy the top physical page in WORLD 0, that is PA_FFFFE000...PA_FFFFFFFF

The following CSRs are defined:

Cache and TLB:
---------------
TBASE - see above
SBASE - see above
TLB_LA1
TLB_DATA1
TLB_LA2
TLB_DATA2
TINV  - if written, invalidates TASK mode TLB entries
SINV  - if written, invalidates SCHEDULER mode TLB entries
CINV  - bit 0: invalidate INST CACHE, bit 1: invalidate DATA CACHE

Perf conuters:
---------------
PERF_CNT0
PERF_CNT1
PERF_CNT2
PERF_CNT3
PERF_CFG0
PERF_CFG1
PERF_CFG2
PERF_CFG3

Interrupt / reset cause:
------------------------
ICAUSE - interrupt cause
ECAUSE - exception cause
EADDR <-- we might not need this as we have xmove to get access to TPC
RCAUSE - reset cause
RADDR



EXECPTION AND INTERRUPT NOTES:
==============================
The following precise exceptions are supported:

- MPF: Page fault: address translation failed - page entry is invalid
- MAV: Access violation: access attempted is not permitted by XWR bits
- MPA: Page access: when page is accessed where A bit is 0
- MPW: Page write: when page is written where D bit is 0
- STF: FILL instruction
- STB: BREAK instruction
- STS: SYSCALL instruction
- SII: invalid instruction
- SUA: unaligned access

Since we do posted writes (or at least should supported it), we can't really do precise bus error exceptions. So, those are not precise:

- IAV: interconnect access violation
- IIA: interconnect invalid address (address decode failure)
- ITF: interconnect target fault (target signaled failure)

These - being imprecise - can't be retried, so if they occur in TASK mode, the only recourse is to terminate the app, and if they happen in SCHEDULER mode, they will reboot, after setting RCAUSE and, if possible, RADDR.

All these sources are mapped into the ECAUSE and RCAUSE registers:

+---+---+---+---+---+---+---+---+---+---+---+---+
|IAV|IIA|ITF|MPF|MAV|MPA|MPW|STF|STB|STS|SII|SUA|
+---+---+---+---+---+---+---+---+---+---+---+---+

There's only a single (level-sensitive) external interrupt source (though we could have a bunch more, since we have a whole register for it):

- EXI

This gets to trigger a transition from TASK to SCHEDULER mode, or gets ignored during SCHEDULER mode (if it's not cleared, it will trigger as soon as the CPU returns to TASK mode).

The IADDR/RADDR registers contain the PC where the interrupt/exception occured.

NOTE: we can use bit-set bit-clear jumps to jump on the first 12 bits of any register, and we have exactly 12 exception sources. Bit 0 (SII) is highest priority, Bit 12 (EXI) is lowest.

NOTE: one can argue that SII/STS/STB/STF should be binary encoded instead of 1-hot encoded. Similarly IAV/IIA/ITF cannot happen at the same time. This could save us 3 bits, but would reduced
      our ability to use the bit-test jumps to quickly get to the handlers. So, I think it's fine as is. If more sources are needed, we're still better off, as a single shift can get us to
      the next 12 bits, which we can continue to branch upon. Really, the interrupt router code is something like this:

	R5 = ECAUSE
	if R5[0] PC = SUA_handler
	h1: if R5[1] PC = SII_handler
	h11: if R5[11] PC = STS_handler
	...
	// if more sources are needed
	R5 >>= 12
	h12: if R5[0] PC = whatever1_handler
	h13: if R5[0] PC = whatever2_handler
	...
	// we don't have any more exception sources: check for interrupts
	// handle return to the appropriate TASK code
	exi_loop:
	R5 = ICAUSE
	if R5 == 0 PC = exi_done
	PC = EXI_handler
	PC = exi_loop
	exi_done:
	...
	
	
	// handler code
	STS_handler:
	// do the things we need to do
	// ...
	// jump back to test for next handler
	PC = h2

We could heve inlined all the handlers and invert the tests, but then in most cases we would do a lot of far jumps (not many bits are set at the same time, usually), which probably
would cause a lot of cache misses.

PERF COUNTERS:
==============

We have 4 performance counters, but lots of events. For now, the following ones are defined:

	ICACHE_MISS
	DCACHE_MISS
	ICACHE_INVALIDATE
	DCACHE_INVALIDATE
	TLB_MISS
	TLB_MISS_1ST_LEVEL
	TLB_MISS_2ND_LEVEL
	INST_FETCH
	PIPELINE_STALL_RAW_HAZARD
	PIPELINE_STALL_WRITE_QUEUE_FLUSH
	PIPELINE_STALL_READ
	PIPELINE_STALL_BRANCH
	PIPELINE_STALL_FETCH
	PIPELINE_STALL_MMU
	PIPELINE_STALL_DCACHE_MISS
	PIPELINE_STALL_MEM_READ
	BRANCH_MIS_PREDICT
	BRANCH_TAKEN
	BRANCH_NOT_TAKEN

SCREEN NOTES:
==============
We can utilize my old-old VGA core here. It at least have been tested, though it's probably due for a proper re-write.

Supported resolutions (needs 120kByte of memory, 7.2MBps @ 60Hz):
1280x768 - monochrome
640x384 - 4-bit colors
320x192 - 16-bit colors

Maybe we can support (needs 150kByte of memory, 9MBps @ 60Hz):
1280x960 - monochrome
640x480 - 4-bit colors
320x240 - 16-bit colors

The system should use a shared memory architecture, where the video controller simply DMAs out of main memory, so overall memory size doesn't matter, only bandwidth needed.
At 60Hz update rate, we will need to allocate about 10MBps of bandwidth to the video subsystem, and we would need to support scan-line replication in a scan-line memory of 1kBytes large.

If the CPU is running at 100MHz, it would need about 200MBps of bandwidth, which is 16-bit SDR DRAM territory. Even with that we can only really sustain these rates with a cache implementation.

At any rate, back to the display controller:

Sprite support:
Sprites should fit in a single BRAM of 1kByte, which gives us:
64x64 in 1-bit colors (2nd bit is for transparency)
32x32 in 4-bit colors (5th bit is for transparency)
16x16 in 15-bit colors (16th bit is for transparency)

Now, of course sprites could live in main memory as well, the only problem is that they would need to be read, potentially at the same time, increasing the (burst) datarate needed by the video subsystem.
That way however pretty much arbitrary number of sprites with arbitrary sizes could be supported.

2D DMA with descriptor-chaining support:
This thing comes very handy, especially for GUI operations: off-screen sections could be copied over to the main screen and with descriptor chains, even overlapping windows could be refreshed with ease.
If source and destination increments are individually controlled, even rudimentary re-scaling could be supported, at the very minimum fill with specific color can be accomplished.
NOTE: this is only true for 16-bit mode. If lesser modes, the DMA works on pixel banks, not individual pixels!!!

MULTI-CORE NOTES:
==================
This is very hard for the same reason that the J90 is hard: unless we have per-core caches, the interconnect gets overloaded and with per-core caches, the coherency protocol becomes a nightmare, unless
that is delegated to SW, which is a completely different kind of nightmare.

If every core implements a write-through cache, things are a little easier as at least the ground truth is always in main memory. So, every cache simply has to snoop the interconnect and invalidate, or update on a hit.
However this logic involves two lookup ports in the tags (one for the CPU, one for the snoop logic), which is problematic though shouldn't be impossible. Races still exist, but they are not any more problematic than races
in general.

The next problem is that of atomic updates or other synchronization primitives. At this point we'd better be on an AXI interconnect, which doesn't really support test-and-set type locked transactions, it's
more of a try-set type setup.

##################################
### Overall, this makes no sense.
##################################

At this point we're much better off using a commercial core and ISA.

The furthest it's worth taking this core to is to have a relatively fast implementation with only on-chip memories (no cache) or a relatively slow version with off-chip memory (no cache still).

